{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8487fc1-08cd-4c9e-ab46-38c3ee3f2184",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16561fd3-7585-4f49-a4e9-6f5d6e4da993",
   "metadata": {},
   "source": [
    "## Load Data - Create Train Generator - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1616e175-01e0-4e9b-a3d3-279d02c4be99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "5606/5606 [==============================] - 1511s 268ms/step - loss: 0.6376 - accuracy: 0.6551 - val_loss: 0.5931 - val_accuracy: 0.6899\n",
      "Epoch 2/5\n",
      "5606/5606 [==============================] - 1466s 262ms/step - loss: 0.5896 - accuracy: 0.6954 - val_loss: 0.5852 - val_accuracy: 0.6965\n",
      "Epoch 3/5\n",
      "5606/5606 [==============================] - 1466s 261ms/step - loss: 0.5650 - accuracy: 0.7121 - val_loss: 0.5834 - val_accuracy: 0.7003\n",
      "Epoch 4/5\n",
      "5606/5606 [==============================] - 1487s 265ms/step - loss: 0.5337 - accuracy: 0.7326 - val_loss: 0.5888 - val_accuracy: 0.7013\n",
      "Epoch 5/5\n",
      "5606/5606 [==============================] - 1484s 265ms/step - loss: 0.4851 - accuracy: 0.7638 - val_loss: 0.6198 - val_accuracy: 0.6832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fa2d43d930>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from PIL import Image\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data_path = r\"C:\\Users\\kelly\\Desktop\\New folder\\Data_Entry_2017_v2020.csv\"\n",
    "image_dir = r\"C:\\Users\\kelly\\Desktop\\New folder\\images\\image_com\"\n",
    "bbox_path = r\"C:\\Users\\kelly\\Desktop\\New folder\\BBox_List_2017.csv\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "bbox_df = pd.read_csv(bbox_path)\n",
    "\n",
    "# Binary classification: 1 for any disease, 0 for 'No Finding'\n",
    "df['binary_label'] = df['Finding Labels'].apply(lambda x: 0 if x == 'No Finding' else 1)\n",
    "\n",
    "# Split the data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['binary_label'], random_state=42)\n",
    "\n",
    "# Data Generator with Bounding Box Cropping\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, bbox_df, batch_size=16):\n",
    "        self.dataframe = dataframe\n",
    "        self.bbox_df = bbox_df\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / float(self.batch_size)))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.dataframe.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        imgs = []\n",
    "        for _, row in batch.iterrows():\n",
    "            img_path = os.path.join(image_dir, row['Image Index'])\n",
    "            img = self.crop_image_to_bbox(img_path, row['Image Index'])\n",
    "            img = img.resize((224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "        \n",
    "            # Ensure the image has 3 channels\n",
    "            if img_array.shape[-1] == 1:  # Grayscale image, needs to be expanded to 3 channels\n",
    "                img_array = np.repeat(img_array, 3, axis=-1)\n",
    "            elif img_array.shape[-1] > 3:  \n",
    "                img_array = img_array[:, :, :3]  # Keep only the first 3 channels\n",
    "        \n",
    "            img_array = preprocess_input(img_array)  # Preprocess the image for ResNet50\n",
    "            imgs.append(img_array)\n",
    "\n",
    "        imgs = np.stack(imgs)  # Combine into a batch\n",
    "        labels = to_categorical(batch['binary_label'].values, num_classes=2)\n",
    "        return imgs, labels\n",
    "\n",
    "\n",
    "    def crop_image_to_bbox(self, image_path, image_name):\n",
    "        if image_name in self.bbox_df['Image Index'].values:\n",
    "            img = Image.open(image_path)\n",
    "            bbox = self.bbox_df.loc[self.bbox_df['Image Index'] == image_name].iloc[0]\n",
    "            img = img.crop((bbox['Bbox [x'], bbox['y'], bbox['Bbox [x'] + bbox['w'], bbox['y'] + bbox['h]']))\n",
    "            return img\n",
    "        else:\n",
    "            return Image.open(image_path)\n",
    "\n",
    "train_generator = DataGenerator(train_df, bbox_df)\n",
    "val_generator = DataGenerator(val_df, bbox_df)\n",
    "\n",
    "# Model Architecture with Dropout\n",
    "base_model = ResNet50(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6045f818-9efa-4e99-a3b4-99b7c15a729b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"C://Users//kelly//Desktop//New folder//resnet1_bbox\", save_format = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a977930-846c-494b-924e-a471d76fe10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"C://Users//kelly//Desktop//New folder//resnet1_bbox.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f6b46-b004-4bca-891e-794ae9d35e04",
   "metadata": {},
   "source": [
    "## Create Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b854c4d6-142d-4dfd-b7d2-a13065c9f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, bbox_df, image_dir, batch_size=16):\n",
    "        self.image_paths = image_paths\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        imgs = []\n",
    "        for img_path in batch_paths:\n",
    "            img = image.load_img(img_path, target_size=(224, 224))\n",
    "            img_array = image.img_to_array(img)\n",
    "        \n",
    "            # Ensure the image has 3 channels\n",
    "            if img_array.shape[-1] == 1:  # Grayscale image, needs to be expanded to 3 channels\n",
    "                img_array = np.repeat(img_array, 3, axis=-1)\n",
    "            elif img_array.shape[-1] > 3:  \n",
    "                img_array = img_array[:, :, :3]  # Keep only the first 3 channels\n",
    "        \n",
    "            img_array = preprocess_input(img_array)  # Preprocess the image for ResNet50\n",
    "            imgs.append(img_array)\n",
    "\n",
    "        imgs = np.stack(imgs)  # Combine into a batch\n",
    "        \n",
    "        return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ce6e5-06a8-4f98-9688-20a05f98321a",
   "metadata": {},
   "source": [
    "## Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614e5c05-1921-41ae-a72c-3e48d0682ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = r'C:\\Users\\kelly\\Desktop\\New folder\\eval_xray_im'\n",
    "test_image_paths = [os.path.join(test_image_dir, img) for img in os.listdir(test_image_dir)]\n",
    "\n",
    "#Ensure the paths are sorted\n",
    "test_image_paths.sort()\n",
    "\n",
    "test_generator = TestDataGenerator(test_image_paths, bbox_df, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc4b098-c6f3-4345-9359-8bebe9a092bf",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1beb4eab-b060-4c17-8b69-945aba35da90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 22s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "np.save(\"C://Users//kelly//Desktop//New folder//resnet1_bbox//predictions_resnet1.npy\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73bba18e-1dcb-46ad-9dff-b3241e02e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare submission\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': [os.path.basename(path) for path in test_image_paths],\n",
    "    'Label': predicted_classes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8384a61c-e78f-43ff-916d-96eecedcf754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>05995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>05996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>05997.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>05998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>05999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  Label\n",
       "0     00000.jpg      0\n",
       "1     00001.jpg      1\n",
       "2     00002.jpg      1\n",
       "3     00003.jpg      0\n",
       "4     00004.jpg      1\n",
       "...         ...    ...\n",
       "5995  05995.jpg      1\n",
       "5996  05996.jpg      1\n",
       "5997  05997.jpg      0\n",
       "5998  05998.jpg      1\n",
       "5999  05999.jpg      1\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5dc227e2-d64c-423a-88c1-3b0b3a5150e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_csv_path = 'submission.csv'\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "print(f\"Submission file saved to {submission_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14ab09d-25ca-4f4c-a5f8-10562a0f4576",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
