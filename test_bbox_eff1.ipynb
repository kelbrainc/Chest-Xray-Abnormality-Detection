{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1e80c32-8a9e-4dc0-bf66-929af4b21058",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2e4ae2-9dc9-427b-879a-ef7978fabffc",
   "metadata": {},
   "source": [
    "## Load Data - Create Train Generator - Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83d98c75-81a8-4d69-a2f3-67c0f02d6214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "43941136/43941136 [==============================] - 3s 0us/step\n",
      "Epoch 1/10\n",
      "5606/5606 [==============================] - 2132s 368ms/step - loss: 0.7336 - accuracy: 0.6310 - val_loss: 0.5971 - val_accuracy: 0.6946 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "5606/5606 [==============================] - 2045s 365ms/step - loss: 0.6140 - accuracy: 0.6842 - val_loss: 0.5748 - val_accuracy: 0.7086 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "5606/5606 [==============================] - 2050s 366ms/step - loss: 0.5926 - accuracy: 0.6997 - val_loss: 0.5714 - val_accuracy: 0.7116 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "5606/5606 [==============================] - 2071s 369ms/step - loss: 0.5842 - accuracy: 0.7079 - val_loss: 0.5821 - val_accuracy: 0.7043 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "5606/5606 [==============================] - 2034s 363ms/step - loss: 0.5773 - accuracy: 0.7132 - val_loss: 0.5719 - val_accuracy: 0.7213 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "5606/5606 [==============================] - 2020s 360ms/step - loss: 0.5710 - accuracy: 0.7172 - val_loss: 0.5717 - val_accuracy: 0.7173 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "5606/5606 [==============================] - ETA: 0s - loss: 0.5653 - accuracy: 0.7226\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "5606/5606 [==============================] - 1994s 356ms/step - loss: 0.5653 - accuracy: 0.7226 - val_loss: 0.5743 - val_accuracy: 0.7127 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "5606/5606 [==============================] - 2011s 359ms/step - loss: 0.5425 - accuracy: 0.7364 - val_loss: 0.5656 - val_accuracy: 0.7212 - lr: 2.0000e-05\n",
      "Epoch 9/10\n",
      "5606/5606 [==============================] - 2011s 359ms/step - loss: 0.5305 - accuracy: 0.7459 - val_loss: 0.5651 - val_accuracy: 0.7218 - lr: 2.0000e-05\n",
      "Epoch 10/10\n",
      "5606/5606 [==============================] - 2005s 358ms/step - loss: 0.5202 - accuracy: 0.7509 - val_loss: 0.5704 - val_accuracy: 0.7230 - lr: 2.0000e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB3, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, BatchNormalization, Dropout, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Load dataset and bounding box information\n",
    "data_path = r\"C:\\Users\\kelly\\Desktop\\New folder\\Data_Entry_2017_v2020.csv\"\n",
    "bbox_path = r\"C:\\Users\\kelly\\Desktop\\New folder\\BBox_List_2017.csv\"\n",
    "image_dir = r\"C:\\Users\\kelly\\Desktop\\New folder\\images\\image_com\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "bbox_df = pd.read_csv(bbox_path)\n",
    "df['binary_label'] = df['Finding Labels'].apply(lambda x: 0 if x == 'No Finding' else 1)\n",
    "\n",
    "# Split data\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, stratify=df['binary_label'], random_state=42)\n",
    "\n",
    "# Instantiate the ImageDataGenerator with the augmentations\n",
    "augmentation_datagen = ImageDataGenerator(\n",
    "    rotation_range=10,       # Degree range for random rotations\n",
    "    width_shift_range=0.1,   # Ranges (as a fraction of total width) for random horizontal shifts\n",
    "    height_shift_range=0.1,  # Ranges (as a fraction of total height) for random vertical shifts\n",
    "    shear_range=0.1,         # Shearing intensity (shear angle in degrees)\n",
    "    zoom_range=0.1,          # Range for random zoom\n",
    "    horizontal_flip=False,    \n",
    "    fill_mode='nearest'      # Strategy for filling in newly created pixels\n",
    ")\n",
    "\n",
    "class BBoxDataGenerator(Sequence):\n",
    "    def __init__(self, dataframe, bbox_df, image_dir, batch_size=16, augmentations=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.bbox_df = bbox_df\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.augmentations = augmentations\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.dataframe) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.dataframe.iloc[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        imgs, labels = [], []\n",
    "        for _, row in batch.iterrows():\n",
    "            img_path = os.path.join(self.image_dir, row['Image Index'])\n",
    "            img = self.crop_and_process_image(img_path, row['Image Index'])\n",
    "            if self.augmentations:\n",
    "                img = self.augmentations.random_transform(img)\n",
    "            imgs.append(img)\n",
    "            labels.append(row['binary_label'])\n",
    "        return np.array(imgs), to_categorical(labels, num_classes=2)\n",
    "    \n",
    "    def crop_and_process_image(self, img_path, img_name):\n",
    "        if img_name in self.bbox_df['Image Index'].values:\n",
    "            bbox = self.bbox_df[self.bbox_df['Image Index'] == img_name].iloc[0]\n",
    "            img = Image.open(img_path).convert('L').crop((bbox['Bbox [x'], bbox['y'], bbox['Bbox [x']+bbox['w'], bbox['y']+bbox['h]']))\n",
    "        else:\n",
    "            img = Image.open(img_path).convert('L')\n",
    "        img = img.resize((224, 224))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.repeat(img, 3, axis=-1)  # Ensure img has shape (height, width, 1)\n",
    "        return preprocess_input(img)\n",
    "\n",
    "\n",
    "train_gen = BBoxDataGenerator(train_df, bbox_df, image_dir, batch_size=16, augmentations=augmentation_datagen)\n",
    "val_gen = BBoxDataGenerator(val_df, bbox_df, image_dir, batch_size=16)  # No augmentations for validation data\n",
    "\n",
    "# Model with Batch Normalization, Dropout\n",
    "base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(1024, activation ='relu')(x)\n",
    "x = Dropout(0.3)(x) \n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "#Train all layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "#Compile model\n",
    "optimizer=Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=4, min_lr=1e-6, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=10,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bbaf3e9-9f3c-4674-a56b-d2f3e338d1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"C://Users//kelly//Desktop//New folder//efficientnet1_bbox\", save_format = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb75f39d-548e-46b7-b06c-6fc028232ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"C://Users//kelly//Desktop//New folder//efficientnet1_bbox.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6c706-92db-4bd4-a0a7-00b30678bae0",
   "metadata": {},
   "source": [
    "## Create Test Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75b8b407-cd33-40d3-b216-a8ea8688585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataGenerator(Sequence):\n",
    "    def __init__(self, image_paths, bbox_df, image_dir, batch_size=16):\n",
    "        self.image_paths = image_paths\n",
    "        self.bbox_df = bbox_df\n",
    "        self.image_dir = image_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_paths = self.image_paths[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        imgs = [self.crop_and_process_image(os.path.join(self.image_dir, img_path), img_path) for img_path in batch_paths]\n",
    "        return np.array(imgs)\n",
    "    \n",
    "    def crop_and_process_image(self, img_path, img_name):\n",
    "        if img_name in self.bbox_df['Image Index'].values:\n",
    "            bbox = self.bbox_df[self.bbox_df['Image Index'] == img_name].iloc[0]\n",
    "            img = Image.open(img_path).convert('L').crop((bbox['Bbox [x'], bbox['y'], bbox['Bbox [x']+bbox['w'], bbox['y']+bbox['h]']))\n",
    "        else:\n",
    "            img = Image.open(img_path).convert('L')\n",
    "        img = img.resize((224, 224))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.repeat(img, 3, axis=-1)  # Convert grayscale to RGB\n",
    "        return preprocess_input(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a4d84-7b0e-4a50-8056-ed7f8fde6e84",
   "metadata": {},
   "source": [
    "## Load Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02671ab-cb2a-4978-a375-4bf130fb5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = r\"C:\\Users\\kelly\\Desktop\\New folder\\eval_xray_im\"\n",
    "test_image_paths = [os.path.join(test_image_dir, img) for img in os.listdir(test_image_dir)]\n",
    "\n",
    "# Ensure the paths are sorted\n",
    "test_image_paths.sort()\n",
    "\n",
    "test_generator = TestDataGenerator(test_image_paths, bbox_df, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5645af67-2da1-4304-8f4c-ae00dbd0ecc0",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e220deb8-4f8c-41df-a35e-eab5796169f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 22s 55ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_generator)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "np.save(\"C://Users//kelly//Desktop//New folder//efficientnet1_bbox//predictions_efficientnet1.npy\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5226cffb-4056-4f00-9544-cd1ec2cef5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare submission dataframe\n",
    "submission_df = pd.DataFrame({\n",
    "    'Id': [os.path.basename(path) for path in test_image_paths],\n",
    "    'Label': predicted_classes\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b5acbd-16a3-4594-bb7f-a6427b823c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00001.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00002.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00003.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00004.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>05995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5996</th>\n",
       "      <td>05996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5997</th>\n",
       "      <td>05997.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5998</th>\n",
       "      <td>05998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5999</th>\n",
       "      <td>05999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id  Label\n",
       "0     00000.jpg      0\n",
       "1     00001.jpg      1\n",
       "2     00002.jpg      1\n",
       "3     00003.jpg      0\n",
       "4     00004.jpg      1\n",
       "...         ...    ...\n",
       "5995  05995.jpg      1\n",
       "5996  05996.jpg      1\n",
       "5997  05997.jpg      0\n",
       "5998  05998.jpg      1\n",
       "5999  05999.jpg      1\n",
       "\n",
       "[6000 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f0109ff-6b29-4179-9598-db21dc7568cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved to submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_csv_path = 'submission.csv'\n",
    "submission_df.to_csv(submission_csv_path, index=False)\n",
    "print(f\"Submission file saved to {submission_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c0ca36-186d-4c4a-a46c-502db9d85500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
